{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "560ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "03d0f970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>reviewer_a</th>\n",
       "      <th>reviewer_b</th>\n",
       "      <th>technical_quality</th>\n",
       "      <th>constructiveness</th>\n",
       "      <th>clarity</th>\n",
       "      <th>overall_quality</th>\n",
       "      <th>review_a</th>\n",
       "      <th>review_b</th>\n",
       "      <th>vote_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7tppsuo8kyq</td>\n",
       "      <td>acl_2024_s59</td>\n",
       "      <td>barebones</td>\n",
       "      <td>multi_agent_with_knowledge</td>\n",
       "      <td>👉  B is better</td>\n",
       "      <td>👉  B is better</td>\n",
       "      <td>👉  B is better</td>\n",
       "      <td>👉  B is better</td>\n",
       "      <td>Here are my main feedback comments as a peer r...</td>\n",
       "      <td>Critical Review of \"Zero-Shot Cross-Lingual Re...</td>\n",
       "      <td>2024-09-08 19:41:00.624620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7tppsuo8kyq</td>\n",
       "      <td>acl_2024_s59</td>\n",
       "      <td>multi_agent_with_knowledge</td>\n",
       "      <td>liang_etal</td>\n",
       "      <td>👈  A is better</td>\n",
       "      <td>👈  A is better</td>\n",
       "      <td>👈  A is better</td>\n",
       "      <td>👈  A is better</td>\n",
       "      <td>Critical Review of \"Zero-Shot Cross-Lingual Re...</td>\n",
       "      <td>Review outline:\\n\\n1. Significance and novelty...</td>\n",
       "      <td>2024-09-08 19:41:16.496030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7tppsuo8kyq</td>\n",
       "      <td>acl_2024_s59</td>\n",
       "      <td>multi_agent_with_knowledge</td>\n",
       "      <td>multi_agent_without_knowledge</td>\n",
       "      <td>👈  A is better</td>\n",
       "      <td>👈  A is better</td>\n",
       "      <td>👈  A is better</td>\n",
       "      <td>👈  A is better</td>\n",
       "      <td>Critical Review of \"Zero-Shot Cross-Lingual Re...</td>\n",
       "      <td>Critical Review of \"Zero-Shot Cross-Lingual Re...</td>\n",
       "      <td>2024-09-08 19:41:48.048705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id      paper_id                  reviewer_a  \\\n",
       "0  7tppsuo8kyq  acl_2024_s59                   barebones   \n",
       "1  7tppsuo8kyq  acl_2024_s59  multi_agent_with_knowledge   \n",
       "2  7tppsuo8kyq  acl_2024_s59  multi_agent_with_knowledge   \n",
       "\n",
       "                      reviewer_b technical_quality constructiveness  \\\n",
       "0     multi_agent_with_knowledge    👉  B is better   👉  B is better   \n",
       "1                     liang_etal    👈  A is better   👈  A is better   \n",
       "2  multi_agent_without_knowledge    👈  A is better   👈  A is better   \n",
       "\n",
       "          clarity overall_quality  \\\n",
       "0  👉  B is better  👉  B is better   \n",
       "1  👈  A is better  👈  A is better   \n",
       "2  👈  A is better  👈  A is better   \n",
       "\n",
       "                                            review_a  \\\n",
       "0  Here are my main feedback comments as a peer r...   \n",
       "1  Critical Review of \"Zero-Shot Cross-Lingual Re...   \n",
       "2  Critical Review of \"Zero-Shot Cross-Lingual Re...   \n",
       "\n",
       "                                            review_b  \\\n",
       "0  Critical Review of \"Zero-Shot Cross-Lingual Re...   \n",
       "1  Review outline:\\n\\n1. Significance and novelty...   \n",
       "2  Critical Review of \"Zero-Shot Cross-Lingual Re...   \n",
       "\n",
       "                   vote_time  \n",
       "0 2024-09-08 19:41:00.624620  \n",
       "1 2024-09-08 19:41:16.496030  \n",
       "2 2024-09-08 19:41:48.048705  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"arena_votes/arena_votes.jsonl\", lines=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79cfeb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reviews: 140\n"
     ]
    }
   ],
   "source": [
    "# Total number of reviews\n",
    "num_reviews = df.shape[0]\n",
    "print(f\"Total number of reviews: {num_reviews}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a4ce8d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "Win rate for multi-agent with knowledge: 0.46\n",
      "Win rate for multi-agent without knowledge: 0.352112676056338\n",
      "Win rate for Liang et al.: 0.2641509433962264\n",
      "Win rate for Barebones: 0.44\n",
      "Win rate for Human Reviewers: 0.2903225806451613\n"
     ]
    }
   ],
   "source": [
    "# Total wins for each model:\n",
    "\n",
    "total_wins_multi_with_knowledge = sum((df['reviewer_a'] == 'multi_agent_with_knowledge') & (df['overall_quality'] == '👈  A is better') | \n",
    "                                 (df['reviewer_b'] == 'multi_agent_with_knowledge') & (df['overall_quality'] == '👉  B is better'))\n",
    "total_wins_multi_no_knowledge = sum((df['reviewer_a'] == 'multi_agent_without_knowledge') & (df['overall_quality'] == '👈  A is better') | \n",
    "                                 (df['reviewer_b'] == 'multi_agent_without_knowledge') & (df['overall_quality'] == '👉  B is better'))\n",
    "total_wins_liang_etal = sum((df['reviewer_a'] == 'liang_etal') & (df['overall_quality'] == '👈  A is better') | \n",
    "                                 (df['reviewer_b'] == 'liang_etal') & (df['overall_quality'] == '👉  B is better'))\n",
    "total_wins_barebones = sum((df['reviewer_a'] == 'barebones') & (df['overall_quality'] == '👈  A is better') | \n",
    "                                 (df['reviewer_b'] == 'barebones') & (df['overall_quality'] == '👉  B is better'))\n",
    "total_wins_human = sum((df['reviewer_a'] == 'human_reviewer') & (df['overall_quality'] == '👈  A is better') | \n",
    "                                 (df['reviewer_b'] == 'human_reviewer') & (df['overall_quality'] == '👉  B is better'))\n",
    "\n",
    "# Total Appearances\n",
    "appearances_multi_agent_with_knowledge = sum((df['reviewer_a'] == 'multi_agent_with_knowledge') | (df['reviewer_b'] == 'multi_agent_with_knowledge'))\n",
    "appearances_multi_agent_without_knowledge = sum((df['reviewer_a'] == 'multi_agent_without_knowledge') | (df['reviewer_b'] == 'multi_agent_without_knowledge'))\n",
    "appearances_liang_et_al = sum((df['reviewer_a'] == 'liang_etal') | (df['reviewer_b'] == 'liang_etal'))\n",
    "appearances_barebones = sum((df['reviewer_a'] == 'barebones') | (df['reviewer_b'] == 'barebones'))\n",
    "appearances_human = sum((df['reviewer_a'] == 'human_reviewer') | (df['reviewer_b'] == 'human_reviewer'))\n",
    "\n",
    "# Win Frequency\n",
    "relative_wins_multi_agent_with_knowledge = total_wins_multi_with_knowledge / appearances_multi_agent_with_knowledge\n",
    "relative_wins_multi_agent_without_knowledge = total_wins_multi_no_knowledge / appearances_multi_agent_without_knowledge\n",
    "relative_wins_liang_etal = total_wins_liang_etal / appearances_liang_et_al\n",
    "relative_wins_barebones = total_wins_barebones / appearances_barebones\n",
    "relative_wins_human = total_wins_human / appearances_human\n",
    "\n",
    "print(total_wins_multi_with_knowledge)\n",
    "print(f\"Win rate for multi-agent with knowledge: {relative_wins_multi_agent_with_knowledge}\")\n",
    "print(f\"Win rate for multi-agent without knowledge: {relative_wins_multi_agent_without_knowledge}\")\n",
    "print(f\"Win rate for Liang et al.: {relative_wins_liang_etal}\")\n",
    "print(f\"Win rate for Barebones: {relative_wins_barebones}\")\n",
    "print(f\"Win rate for Human Reviewers: {relative_wins_human}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1dbf81fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barebones in technical_quality:\n",
      " - Wins: 32\n",
      " - Appearances: 75\n",
      " - Non-win outcomes (Both are bad or Tie): 12\n",
      " - Win rate: 42.67%\n",
      "\n",
      "barebones in constructiveness:\n",
      " - Wins: 29\n",
      " - Appearances: 75\n",
      " - Non-win outcomes (Both are bad or Tie): 16\n",
      " - Win rate: 38.67%\n",
      "\n",
      "barebones in clarity:\n",
      " - Wins: 29\n",
      " - Appearances: 75\n",
      " - Non-win outcomes (Both are bad or Tie): 16\n",
      " - Win rate: 38.67%\n",
      "\n",
      "barebones in overall_quality:\n",
      " - Wins: 33\n",
      " - Appearances: 75\n",
      " - Non-win outcomes (Both are bad or Tie): 12\n",
      " - Win rate: 44.00%\n",
      "\n",
      "multi_agent_with_knowledge in technical_quality:\n",
      " - Wins: 22\n",
      " - Appearances: 50\n",
      " - Non-win outcomes (Both are bad or Tie): 23\n",
      " - Win rate: 44.00%\n",
      "\n",
      "multi_agent_with_knowledge in constructiveness:\n",
      " - Wins: 23\n",
      " - Appearances: 50\n",
      " - Non-win outcomes (Both are bad or Tie): 25\n",
      " - Win rate: 46.00%\n",
      "\n",
      "multi_agent_with_knowledge in clarity:\n",
      " - Wins: 22\n",
      " - Appearances: 50\n",
      " - Non-win outcomes (Both are bad or Tie): 24\n",
      " - Win rate: 44.00%\n",
      "\n",
      "multi_agent_with_knowledge in overall_quality:\n",
      " - Wins: 23\n",
      " - Appearances: 50\n",
      " - Non-win outcomes (Both are bad or Tie): 23\n",
      " - Win rate: 46.00%\n",
      "\n",
      "liang_etal in technical_quality:\n",
      " - Wins: 15\n",
      " - Appearances: 53\n",
      " - Non-win outcomes (Both are bad or Tie): 8\n",
      " - Win rate: 28.30%\n",
      "\n",
      "liang_etal in constructiveness:\n",
      " - Wins: 13\n",
      " - Appearances: 53\n",
      " - Non-win outcomes (Both are bad or Tie): 14\n",
      " - Win rate: 24.53%\n",
      "\n",
      "liang_etal in clarity:\n",
      " - Wins: 14\n",
      " - Appearances: 53\n",
      " - Non-win outcomes (Both are bad or Tie): 12\n",
      " - Win rate: 26.42%\n",
      "\n",
      "liang_etal in overall_quality:\n",
      " - Wins: 14\n",
      " - Appearances: 53\n",
      " - Non-win outcomes (Both are bad or Tie): 8\n",
      " - Win rate: 26.42%\n",
      "\n",
      "multi_agent_without_knowledge in technical_quality:\n",
      " - Wins: 26\n",
      " - Appearances: 71\n",
      " - Non-win outcomes (Both are bad or Tie): 26\n",
      " - Win rate: 36.62%\n",
      "\n",
      "multi_agent_without_knowledge in constructiveness:\n",
      " - Wins: 22\n",
      " - Appearances: 71\n",
      " - Non-win outcomes (Both are bad or Tie): 29\n",
      " - Win rate: 30.99%\n",
      "\n",
      "multi_agent_without_knowledge in clarity:\n",
      " - Wins: 25\n",
      " - Appearances: 71\n",
      " - Non-win outcomes (Both are bad or Tie): 27\n",
      " - Win rate: 35.21%\n",
      "\n",
      "multi_agent_without_knowledge in overall_quality:\n",
      " - Wins: 25\n",
      " - Appearances: 71\n",
      " - Non-win outcomes (Both are bad or Tie): 26\n",
      " - Win rate: 35.21%\n",
      "\n",
      "human_reviewer in technical_quality:\n",
      " - Wins: 9\n",
      " - Appearances: 31\n",
      " - Non-win outcomes (Both are bad or Tie): 3\n",
      " - Win rate: 29.03%\n",
      "\n",
      "human_reviewer in constructiveness:\n",
      " - Wins: 9\n",
      " - Appearances: 31\n",
      " - Non-win outcomes (Both are bad or Tie): 4\n",
      " - Win rate: 29.03%\n",
      "\n",
      "human_reviewer in clarity:\n",
      " - Wins: 8\n",
      " - Appearances: 31\n",
      " - Non-win outcomes (Both are bad or Tie): 5\n",
      " - Win rate: 25.81%\n",
      "\n",
      "human_reviewer in overall_quality:\n",
      " - Wins: 9\n",
      " - Appearances: 31\n",
      " - Non-win outcomes (Both are bad or Tie): 3\n",
      " - Win rate: 29.03%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categories = ['technical_quality', 'constructiveness', 'clarity', 'overall_quality']\n",
    "possible_outcomes = ['👈  A is better', '👉  B is better', '👎  Both are bad', '🤝  Tie']\n",
    "models = pd.unique(df[['reviewer_a', 'reviewer_b']].values.ravel())\n",
    "\n",
    "wins = {model: {category: 0 for category in categories} for model in models}\n",
    "appearances = {model: {category: 0 for category in categories} for model in models}\n",
    "non_wins = {model: {category: 0 for category in categories} for model in models}\n",
    "\n",
    "# For each category, count appearances and wins\n",
    "for category in categories:\n",
    "    for model in models:\n",
    "        # Count total appearances (either in reviewer_a or reviewer_b) without double-counting\n",
    "        appearances[model][category] = sum(((df['reviewer_a'] == model) | (df['reviewer_b'] == model)))\n",
    "\n",
    "        # Count wins for reviewer_a\n",
    "        wins[model][category] += sum((df['reviewer_a'] == model) & (df[category] == '👈  A is better'))\n",
    "\n",
    "        # Count wins for reviewer_b\n",
    "        wins[model][category] += sum((df['reviewer_b'] == model) & (df[category] == '👉  B is better'))\n",
    "\n",
    "        # Count non-win outcomes (Both are bad or Tie)\n",
    "        non_wins[model][category] += sum((df['reviewer_a'] == model) & (df[category].isin(['👎  Both are bad', '🤝  Tie'])))\n",
    "        non_wins[model][category] += sum((df['reviewer_b'] == model) & (df[category].isin(['👎  Both are bad', '🤝  Tie'])))\n",
    "\n",
    "# Example to print total wins, appearances, and non-wins by category for each model\n",
    "for model in models:\n",
    "    for category in categories:\n",
    "        total_wins = wins[model][category]\n",
    "        total_appearances = appearances[model][category]\n",
    "        total_non_wins = non_wins[model][category]\n",
    "        \n",
    "        print(f'{model} in {category}:')\n",
    "        print(f' - Wins: {total_wins}')\n",
    "        print(f' - Appearances: {total_appearances}')\n",
    "        print(f' - Non-win outcomes (Both are bad or Tie): {total_non_wins}')\n",
    "        print(f' - Win rate: {(total_wins / total_appearances * 100) if total_appearances > 0 else 0:.2f}%')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3670ace4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Win Rates: \n",
      "                               barebones  multi_agent_with_knowledge  \\\n",
      "barebones                            NaN                        0.00   \n",
      "multi_agent_with_knowledge          1.00                         NaN   \n",
      "liang_etal                          0.15                        0.00   \n",
      "multi_agent_without_knowledge       0.80                        0.09   \n",
      "human_reviewer                      0.38                         NaN   \n",
      "\n",
      "                               liang_etal  multi_agent_without_knowledge  \\\n",
      "barebones                            0.67                           0.05   \n",
      "multi_agent_with_knowledge           1.00                           0.41   \n",
      "liang_etal                            NaN                            NaN   \n",
      "multi_agent_without_knowledge         NaN                            NaN   \n",
      "human_reviewer                       0.31                           0.00   \n",
      "\n",
      "                               human_reviewer  \n",
      "barebones                                0.46  \n",
      "multi_agent_with_knowledge                NaN  \n",
      "liang_etal                               0.62  \n",
      "multi_agent_without_knowledge            1.00  \n",
      "human_reviewer                            NaN  \n"
     ]
    }
   ],
   "source": [
    "matrix_wins = pd.DataFrame(0, index = models, columns = models)\n",
    "matrix_comparisons = pd.DataFrame(0, index = models, columns = models)\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    reviewer_a = row['reviewer_a']\n",
    "    reviewer_b = row['reviewer_b']\n",
    "    outcome = row['overall_quality']\n",
    "    \n",
    "    \n",
    "    matrix_comparisons.loc[reviewer_a, reviewer_b] += 1\n",
    "    matrix_comparisons.loc[reviewer_b, reviewer_a] += 1\n",
    "    \n",
    "    if outcome == '👈  A is better':\n",
    "        matrix_wins.loc[reviewer_a, reviewer_b] +=1\n",
    "    elif outcome == '👉  B is better':\n",
    "        matrix_wins.loc[reviewer_b, reviewer_a] += 1\n",
    "    \n",
    "matrix_win_rate = matrix_wins / matrix_comparisons\n",
    "matrix_win_rate[matrix_comparisons == 0] = np.nan\n",
    "\n",
    "matrix_win_rate = matrix_win_rate.round(2)\n",
    "matrix_win_rate_display = matrix_win_rate.fillna('N/A')\n",
    "\n",
    "print(\"Pairwise Win Rates: \")\n",
    "print(matrix_win_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6938ee9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Win Rates (row=winner, column=loser):\n",
      "╒═══════════════════════════════╤═════════════╤══════════════════════════════╤══════════════╤═════════════════════════════════╤══════════════════╕\n",
      "│                               │   barebones │   multi_agent_with_knowledge │   liang_etal │   multi_agent_without_knowledge │   human_reviewer │\n",
      "╞═══════════════════════════════╪═════════════╪══════════════════════════════╪══════════════╪═════════════════════════════════╪══════════════════╡\n",
      "│ barebones                     │      nan    │                         0    │         0.67 │                            0.05 │             0.46 │\n",
      "├───────────────────────────────┼─────────────┼──────────────────────────────┼──────────────┼─────────────────────────────────┼──────────────────┤\n",
      "│ multi_agent_with_knowledge    │        1    │                       nan    │         1    │                            0.41 │           nan    │\n",
      "├───────────────────────────────┼─────────────┼──────────────────────────────┼──────────────┼─────────────────────────────────┼──────────────────┤\n",
      "│ liang_etal                    │        0.15 │                         0    │       nan    │                          nan    │             0.62 │\n",
      "├───────────────────────────────┼─────────────┼──────────────────────────────┼──────────────┼─────────────────────────────────┼──────────────────┤\n",
      "│ multi_agent_without_knowledge │        0.8  │                         0.09 │       nan    │                          nan    │             1    │\n",
      "├───────────────────────────────┼─────────────┼──────────────────────────────┼──────────────┼─────────────────────────────────┼──────────────────┤\n",
      "│ human_reviewer                │        0.38 │                       nan    │         0.31 │                            0    │           nan    │\n",
      "╘═══════════════════════════════╧═════════════╧══════════════════════════════╧══════════════╧═════════════════════════════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "print(\"Pairwise Win Rates (row=winner, column=loser):\")\n",
    "print(tabulate(matrix_win_rate, headers='keys', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f72856d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper Triangular Pairwise Comparison Matrix:\n",
      "                              barebones multi_agent_with_knowledge  \\\n",
      "barebones                                  W: 0, L: 3, T: 0, BB: 0   \n",
      "multi_agent_with_knowledge                                           \n",
      "liang_etal                                                           \n",
      "multi_agent_without_knowledge                                        \n",
      "human_reviewer                                                       \n",
      "\n",
      "                                             liang_etal  \\\n",
      "barebones                      W: 26, L: 6, T: 1, BB: 6   \n",
      "multi_agent_with_knowledge      W: 1, L: 0, T: 0, BB: 0   \n",
      "liang_etal                                                \n",
      "multi_agent_without_knowledge                             \n",
      "human_reviewer                                            \n",
      "\n",
      "                              multi_agent_without_knowledge  \\\n",
      "barebones                          W: 1, L: 16, T: 3, BB: 0   \n",
      "multi_agent_with_knowledge        W: 19, L: 4, T: 23, BB: 0   \n",
      "liang_etal                                              N/A   \n",
      "multi_agent_without_knowledge                                 \n",
      "human_reviewer                                                \n",
      "\n",
      "                                        human_reviewer  \n",
      "barebones                      W: 6, L: 5, T: 2, BB: 0  \n",
      "multi_agent_with_knowledge                         N/A  \n",
      "liang_etal                     W: 8, L: 4, T: 0, BB: 1  \n",
      "multi_agent_without_knowledge  W: 5, L: 0, T: 0, BB: 0  \n",
      "human_reviewer                                          \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize matrices for different outcomes\n",
    "matrix_wins = pd.DataFrame(0, index=models, columns=models)\n",
    "matrix_losses = pd.DataFrame(0, index=models, columns=models)\n",
    "matrix_ties = pd.DataFrame(0, index=models, columns=models)\n",
    "matrix_both_bad = pd.DataFrame(0, index=models, columns=models)\n",
    "matrix_comparisons = pd.DataFrame(0, index=models, columns=models)\n",
    "\n",
    "# Iterate through the DataFrame to populate the matrices\n",
    "for i, row in df.iterrows():\n",
    "    reviewer_a = row['reviewer_a']\n",
    "    reviewer_b = row['reviewer_b']\n",
    "    outcome = row['overall_quality']\n",
    "    \n",
    "    # Increment total comparisons for both models\n",
    "    matrix_comparisons.loc[reviewer_a, reviewer_b] += 1\n",
    "    matrix_comparisons.loc[reviewer_b, reviewer_a] += 1\n",
    "    \n",
    "    # Record different outcomes\n",
    "    if outcome == '👈  A is better':\n",
    "        matrix_wins.loc[reviewer_a, reviewer_b] += 1\n",
    "        matrix_losses.loc[reviewer_b, reviewer_a] += 1\n",
    "    elif outcome == '👉  B is better':\n",
    "        matrix_wins.loc[reviewer_b, reviewer_a] += 1\n",
    "        matrix_losses.loc[reviewer_a, reviewer_b] += 1\n",
    "    elif outcome == '🤝  Tie':\n",
    "        matrix_ties.loc[reviewer_a, reviewer_b] += 1\n",
    "        matrix_ties.loc[reviewer_b, reviewer_a] += 1\n",
    "    elif outcome == '👎  Both are bad':\n",
    "        matrix_both_bad.loc[reviewer_a, reviewer_b] += 1\n",
    "        matrix_both_bad.loc[reviewer_b, reviewer_a] += 1\n",
    "\n",
    "# Create an upper triangular matrix combining the outcomes\n",
    "upper_triangular_matrix = pd.DataFrame('', index=models, columns=models)\n",
    "\n",
    "for i, row_model in enumerate(models):\n",
    "    for j, col_model in enumerate(models):\n",
    "        if i < j:  # Only fill the upper triangular part\n",
    "            win_count = matrix_wins.loc[row_model, col_model]\n",
    "            loss_count = matrix_losses.loc[row_model, col_model]\n",
    "            tie_count = matrix_ties.loc[row_model, col_model]\n",
    "            both_bad_count = matrix_both_bad.loc[row_model, col_model]\n",
    "            total_comparisons = matrix_comparisons.loc[row_model, col_model]\n",
    "            \n",
    "            if total_comparisons > 0:\n",
    "                upper_triangular_matrix.loc[row_model, col_model] = f\"W: {win_count}, L: {loss_count}, T: {tie_count}, BB: {both_bad_count}\"\n",
    "            else:\n",
    "                upper_triangular_matrix.loc[row_model, col_model] = \"N/A\"\n",
    "\n",
    "# Display the upper triangular matrix\n",
    "print(\"Upper Triangular Pairwise Comparison Matrix:\")\n",
    "print(upper_triangular_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ced88c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Win Rates:\n",
      "(Row vs. Column)\n",
      "╒═══════════════════════════════╤═════════════╤══════════════════════════════╤══════════════════════════╤═════════════════════════════════╤═════════════════════════╕\n",
      "│                               │ barebones   │ multi_agent_with_knowledge   │ liang_etal               │ multi_agent_without_knowledge   │ human_reviewer          │\n",
      "╞═══════════════════════════════╪═════════════╪══════════════════════════════╪══════════════════════════╪═════════════════════════════════╪═════════════════════════╡\n",
      "│ barebones                     │             │ W: 0, L: 3, T: 0, BB: 0      │ W: 26, L: 6, T: 1, BB: 6 │ W: 1, L: 16, T: 3, BB: 0        │ W: 6, L: 5, T: 2, BB: 0 │\n",
      "├───────────────────────────────┼─────────────┼──────────────────────────────┼──────────────────────────┼─────────────────────────────────┼─────────────────────────┤\n",
      "│ multi_agent_with_knowledge    │             │                              │ W: 1, L: 0, T: 0, BB: 0  │ W: 19, L: 4, T: 23, BB: 0       │ N/A                     │\n",
      "├───────────────────────────────┼─────────────┼──────────────────────────────┼──────────────────────────┼─────────────────────────────────┼─────────────────────────┤\n",
      "│ liang_etal                    │             │                              │                          │ N/A                             │ W: 8, L: 4, T: 0, BB: 1 │\n",
      "├───────────────────────────────┼─────────────┼──────────────────────────────┼──────────────────────────┼─────────────────────────────────┼─────────────────────────┤\n",
      "│ multi_agent_without_knowledge │             │                              │                          │                                 │ W: 5, L: 0, T: 0, BB: 0 │\n",
      "├───────────────────────────────┼─────────────┼──────────────────────────────┼──────────────────────────┼─────────────────────────────────┼─────────────────────────┤\n",
      "│ human_reviewer                │             │                              │                          │                                 │                         │\n",
      "╘═══════════════════════════════╧═════════════╧══════════════════════════════╧══════════════════════════╧═════════════════════════════════╧═════════════════════════╛\n",
      "Key: W = Win, L = Loss, T = Tie, BB = Both Bad\n"
     ]
    }
   ],
   "source": [
    "print(\"Pairwise Win Rates:\")\n",
    "print(\"(Row vs. Column)\")\n",
    "print(tabulate(upper_triangular_matrix, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"Key: W = Win, L = Loss, T = Tie, BB = Both Bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2fa129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5dc18c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
